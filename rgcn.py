import torch
import torch.nn.functional as F
from torch_geometric.nn import RGCNConv
from torch_geometric.data import Data, DataLoader
import numpy as np
import json

class RGCNManager:
    """
    R-GCN (Relational Graph Convolutional Network) ë§¤ë‹ˆì € í´ë˜ìŠ¤
    """
    
    def __init__(self):
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.node_features = {}
        self.relation_types = {}
        self.num_relations = 0
        self.feature_dim = 64
        self.hidden_dim = 32
        self.output_dim = 16
        
    def initialize_model(self, num_nodes, num_relations):
        """R-GCN ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self.num_relations = num_relations
            self.model = RGCNModel(
                num_nodes=num_nodes,
                num_relations=num_relations,
                feature_dim=self.feature_dim,
                hidden_dim=self.hidden_dim,
                output_dim=self.output_dim
            ).to(self.device)
            return True
        except Exception as e:
            print(f"âŒ R-GCN ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def prepare_graph_data(self, graph_data):
        """ê·¸ë˜í”„ ë°ì´í„°ë¥¼ R-GCN ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜"""
        try:
            nodes = graph_data.get('nodes', [])
            edges = graph_data.get('edges', [])
            
            if not nodes or not edges:
                print("âš ï¸ ê·¸ë˜í”„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return None
            
            # ë…¸ë“œ IDë¥¼ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë§¤í•‘
            node_to_idx = {node['id']: i for i, node in enumerate(nodes)}
            
            # ê´€ê³„ íƒ€ì…ì„ ìˆ«ìë¡œ ë§¤í•‘
            relation_types = list(set(edge.get('relation_type', 'unknown') for edge in edges))
            self.relation_types = {rel: i for i, rel in enumerate(relation_types)}
            
            # ì—£ì§€ ì¸ë±ìŠ¤ì™€ ê´€ê³„ íƒ€ì… ìƒì„±
            edge_index = []
            edge_type = []
            
            for edge in edges:
                source = edge.get('source')
                target = edge.get('target')
                rel_type = edge.get('relation_type', 'unknown')
                
                if source in node_to_idx and target in node_to_idx:
                    edge_index.append([node_to_idx[source], node_to_idx[target]])
                    edge_type.append(self.relation_types[rel_type])
            
            if not edge_index:
                print("âš ï¸ ìœ íš¨í•œ ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ë…¸ë“œ íŠ¹ì„± ìƒì„± (ê³ ì • ì°¨ì›ìœ¼ë¡œ ì¡°ì •)
            num_nodes = len(nodes)
            
            # ë…¸ë“œ íŠ¹ì„±ì„ ê³ ì •ëœ feature_dimìœ¼ë¡œ ìƒì„±
            if num_nodes <= self.feature_dim:
                # ë…¸ë“œ ìˆ˜ê°€ ì ìœ¼ë©´ ì›-í•« + íŒ¨ë”©
                node_features = torch.zeros(num_nodes, self.feature_dim).float()
                for i in range(num_nodes):
                    node_features[i, i] = 1.0
            else:
                # ë…¸ë“œ ìˆ˜ê°€ ë§ìœ¼ë©´ í•´ì‹œ ê¸°ë°˜ íŠ¹ì„± ìƒì„±
                node_features = torch.zeros(num_nodes, self.feature_dim).float()
                for i, node in enumerate(nodes):
                    # ë…¸ë“œ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì‹œ íŠ¹ì„± ìƒì„±
                    node_id_hash = hash(node['id']) % self.feature_dim
                    node_features[i, node_id_hash] = 1.0
                    
                    # ë…¸ë“œ íƒ€ì…ì´ ìˆë‹¤ë©´ ì¶”ê°€ íŠ¹ì„±
                    if 'ontology_class' in node:
                        type_hash = hash(node['ontology_class']) % self.feature_dim
                        if type_hash != node_id_hash:
                            node_features[i, type_hash] = 0.5
            
            # PyTorch Geometric ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
            edge_type = torch.tensor(edge_type, dtype=torch.long)
            
            data = Data(
                x=node_features,
                edge_index=edge_index,
                edge_type=edge_type,
                num_nodes=num_nodes
            )
            
            return data, len(relation_types)
            
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return None
    
    def predict(self, graph_data):
        """R-GCNì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰"""
        try:
            print("ğŸ”® R-GCN ì˜ˆì¸¡ ì‹œì‘...")
            
            # ê·¸ë˜í”„ ë°ì´í„° ì¤€ë¹„
            prepared_data = self.prepare_graph_data(graph_data)
            if prepared_data is None:
                return self._fallback_prediction(graph_data)
            
            data, num_relations = prepared_data
            
            # ëª¨ë¸ ì´ˆê¸°í™”
            if not self.initialize_model(data.num_nodes, num_relations):
                return self._fallback_prediction(graph_data)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            self.model.eval()
            with torch.no_grad():
                data = data.to(self.device)
                embeddings = self.model(data.x, data.edge_index, data.edge_type)
                
                # ë…¸ë“œ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
                predictions = self._generate_predictions(embeddings, graph_data)
            
            print("âœ… R-GCN ì˜ˆì¸¡ ì™„ë£Œ!")
            return predictions
            
        except Exception as e:
            print(f"âŒ R-GCN ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._fallback_prediction(graph_data)
    
    def _generate_predictions(self, embeddings, graph_data):
        """ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±"""
        try:
            nodes = graph_data.get('nodes', [])
            predictions = {
                'node_embeddings': embeddings.cpu().numpy().tolist(),
                'predictions': [],
                'confidence_scores': [],
                'relation_recommendations': [],
                'average_confidence': 0.0,  # ì¶”ê°€
                'total_nodes': len(nodes),  # ì¶”ê°€
                'prediction_summary': {}    # ì¶”ê°€
            }
            
            # ê° ë…¸ë“œì— ëŒ€í•œ ì˜ˆì¸¡
            total_confidence = 0.0
            cluster_counts = {'high_importance': 0, 'medium_importance': 0, 'low_importance': 0}
            
            for i, node in enumerate(nodes):
                # ì„ë² ë”© ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                embedding = embeddings[i].cpu().numpy()
                cluster = self._simple_clustering(embedding)
                confidence = float(torch.sigmoid(torch.norm(embeddings[i])))
                
                predictions['predictions'].append({
                    'node_id': node['id'],
                    'predicted_cluster': cluster,
                    'confidence': confidence,
                    'embedding_norm': float(torch.norm(embeddings[i]))
                })
                
                predictions['confidence_scores'].append(confidence)
                total_confidence += confidence
                cluster_counts[cluster] += 1
            
            # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
            predictions['average_confidence'] = total_confidence / max(1, len(nodes))
            predictions['class_distribution'] = cluster_counts  # ìµœìƒìœ„ë¡œ ì´ë™
            predictions['prediction_summary'] = {
                'cluster_distribution': cluster_counts,
                'avg_confidence': predictions['average_confidence'],
                'high_confidence_nodes': sum(1 for c in predictions['confidence_scores'] if c > 0.7),
                'total_predictions': len(predictions['predictions'])
            }
            
            # ê´€ê³„ ì¶”ì²œ (ìƒìœ„ ìœ ì‚¬ë„ ê¸°ë°˜)
            similarities = torch.mm(embeddings, embeddings.t())
            top_pairs = torch.topk(similarities.flatten(), k=min(10, len(nodes)//2))
            
            for idx in top_pairs.indices:
                i, j = divmod(idx.item(), len(nodes))
                if i != j:  # ìê¸° ìì‹  ì œì™¸
                    predictions['relation_recommendations'].append({
                        'source': nodes[i]['id'],
                        'target': nodes[j]['id'],
                        'similarity': float(similarities[i, j]),
                        'recommended_relation': 'similar_to'
                    })
            
            return predictions
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._fallback_prediction(graph_data)
    
    def _simple_clustering(self, embedding):
        """ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§ (ì˜ˆì‹œ)"""
        # ì„ë² ë”©ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì„ ê¸°ì¤€ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
        if embedding[0] > 0.5:
            return "high_importance"
        elif embedding[0] > 0:
            return "medium_importance"
        else:
            return "low_importance"
    
    def _fallback_prediction(self, graph_data):
        """R-GCN ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì˜ˆì¸¡"""
        print("ğŸ”„ ëŒ€ì²´ ì˜ˆì¸¡ ë°©ë²• ì‚¬ìš©...")
        
        nodes = graph_data.get('nodes', [])
        edges = graph_data.get('edges', [])
        
        predictions = {
            'node_embeddings': [],
            'predictions': [],
            'confidence_scores': [],
            'relation_recommendations': [],
            'fallback': True,
            'average_confidence': 0.0,      # ì¶”ê°€
            'total_nodes': len(nodes),      # ì¶”ê°€
            'prediction_summary': {}        # ì¶”ê°€
        }
        
        # ê°„ë‹¨í•œ ê·¸ë˜í”„ ë¶„ì„ ê¸°ë°˜ ì˜ˆì¸¡
        total_confidence = 0.0
        cluster_counts = {'high_importance': 0, 'medium_importance': 0, 'low_importance': 0}
        
        for node in nodes:
            # ë…¸ë“œì˜ ì—°ê²° ì •ë„ ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚°
            degree = sum(1 for edge in edges if edge.get('source') == node['id'] or edge.get('target') == node['id'])
            importance = min(degree / max(1, len(nodes) * 0.1), 1.0)
            cluster = "high_importance" if importance > 0.7 else "medium_importance" if importance > 0.3 else "low_importance"
            
            predictions['predictions'].append({
                'node_id': node['id'],
                'predicted_cluster': cluster,
                'confidence': importance,
                'degree': degree
            })
            
            predictions['confidence_scores'].append(importance)
            predictions['node_embeddings'].append([importance, degree, len(node.get('id', ''))])
            total_confidence += importance
            cluster_counts[cluster] += 1
        
        # í‰ê·  ì‹ ë¢°ë„ ë° ìš”ì•½ ì •ë³´ ì¶”ê°€
        predictions['average_confidence'] = total_confidence / max(1, len(nodes))
        predictions['class_distribution'] = cluster_counts  # ìµœìƒìœ„ë¡œ ì´ë™
        predictions['prediction_summary'] = {
            'cluster_distribution': cluster_counts,
            'avg_confidence': predictions['average_confidence'],
            'high_confidence_nodes': sum(1 for c in predictions['confidence_scores'] if c > 0.7),
            'total_predictions': len(predictions['predictions']),
            'fallback_method': True
        }
        
        return predictions
    
    def get_status(self):
        """R-GCN ë§¤ë‹ˆì €ì˜ í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        try:
            status = {
                'initialized': self.model is not None,
                'device': str(self.device),
                'num_relations': self.num_relations,
                'feature_dim': self.feature_dim,
                'hidden_dim': self.hidden_dim,
                'output_dim': self.output_dim,
                'available': True,
                'torch_available': torch.cuda.is_available(),
                'relation_types': len(self.relation_types)
            }
            return status
        except Exception as e:
            return {
                'initialized': False,
                'available': False,
                'error': str(e),
                'device': 'unknown'
            }


class RGCNModel(torch.nn.Module):
    """R-GCN ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, num_nodes, num_relations, feature_dim, hidden_dim, output_dim):
        super(RGCNModel, self).__init__()
        
        self.num_relations = num_relations
        self.conv1 = RGCNConv(feature_dim, hidden_dim, num_relations)
        self.conv2 = RGCNConv(hidden_dim, output_dim, num_relations)
        self.dropout = torch.nn.Dropout(0.2)
        
    def forward(self, x, edge_index, edge_type):
        # ì²« ë²ˆì§¸ R-GCN ì¸µ
        x = self.conv1(x, edge_index, edge_type)
        x = F.relu(x)
        x = self.dropout(x)
        
        # ë‘ ë²ˆì§¸ R-GCN ì¸µ
        x = self.conv2(x, edge_index, edge_type)
        
        return x