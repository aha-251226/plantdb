import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import networkx as nx
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import RGCNConv, SAGEConv, GATConv, HeteroConv
from torch_geometric.data import Data, HeteroData
import numpy as np
import pdfplumber
import re
import json
import sqlite3
import redis
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
import rdflib
from rdflib import Graph, Namespace, URIRef
import logging
from typing import Dict, List, Tuple, Any, Optional
import io
from datetime import datetime
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import psycopg2
from sqlalchemy import create_engine, text
import pickle
# FAISS ì„ íƒì  ì„í¬íŠ¸
try:
    import faiss
    FAISS_AVAILABLE = True
    # GPU ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    try:
        faiss.StandardGpuResources()
        FAISS_GPU_AVAILABLE = True
    except:
        FAISS_GPU_AVAILABLE = False
except ImportError:
    FAISS_AVAILABLE = False
    FAISS_GPU_AVAILABLE = False
    logger.warning("âš ï¸ FAISS not available. Vector search will be slower.")
import threading
from queue import Queue
import multiprocessing as mp
from functools import lru_cache
import hashlib
import os
from pathlib import Path

# GPU ê°€ì† ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.backends.cudnn.benchmark = True

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Enterprise Multi-GNN Knowledge Graph Analyzer",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseManager:
    """í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì (PostgreSQL + Redis + FAISS)"""
    
    def __init__(self, db_config: Dict[str, str]):
        self.db_config = db_config
        self.pg_engine = None
        self.redis_client = None
        self.faiss_index = None
        self.vector_dimension = 384
        self._init_connections()
    
    def _init_connections(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”"""
        try:
            # PostgreSQL ì—°ê²°
            pg_url = f"postgresql://{self.db_config['pg_user']}:{self.db_config['pg_password']}@{self.db_config['pg_host']}:{self.db_config['pg_port']}/{self.db_config['pg_database']}"
            self.pg_engine = create_engine(pg_url, pool_size=10, max_overflow=20)
            
            # Redis ì—°ê²°
            self.redis_client = redis.Redis(
                host=self.db_config.get('redis_host', 'localhost'),
                port=self.db_config.get('redis_port', 6379),
                db=0,
                decode_responses=True
            )
            
        try:
            # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ë§Œ)
            if FAISS_AVAILABLE:
                if FAISS_GPU_AVAILABLE:
                    # GPU FAISS ì‚¬ìš©
                    res = faiss.StandardGpuResources()
                    self.faiss_index = faiss.GpuIndexFlatIP(res, self.vector_dimension)
                    logger.info("âœ… FAISS-GPU initialized")
                else:
                    # CPU FAISS ì‚¬ìš©
                    self.faiss_index = faiss.IndexFlatIP(self.vector_dimension)
                    logger.info("âœ… FAISS-CPU initialized")
            else:
                self.faiss_index = None
                logger.info("â„¹ï¸ FAISS not available, using alternative vector search")
            
            self._create_tables()
            logger.info("âœ… Database connections established")
            
        except Exception as e:
            logger.error(f"âŒ Database connection failed: {e}")
            # ë¡œì»¬ SQLite í´ë°±
            self.pg_engine = create_engine("sqlite:///knowledge_graph.db")
            self._create_tables()
    
    def _create_tables(self):
        """í…Œì´ë¸” ìƒì„±"""
        with self.pg_engine.connect() as conn:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS documents (
                    id SERIAL PRIMARY KEY,
                    filename VARCHAR(255) NOT NULL,
                    content_hash VARCHAR(64) UNIQUE,
                    fields JSONB,
                    metadata JSONB,
                    quality_score FLOAT,
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding_vector BYTEA
                )
            """))
            
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS field_mappings (
                    id SERIAL PRIMARY KEY,
                    source_field VARCHAR(255),
                    target_field VARCHAR(255),
                    similarity_score FLOAT,
                    mapping_type VARCHAR(50),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS gnn_models (
                    id SERIAL PRIMARY KEY,
                    model_name VARCHAR(100),
                    model_data BYTEA,
                    hyperparameters JSONB,
                    performance_metrics JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            conn.commit()
    
    def save_document(self, doc_data: Dict) -> int:
        """ë¬¸ì„œ ì €ì¥"""
        content_hash = hashlib.sha256(str(doc_data['fields']).encode()).hexdigest()
        
        with self.pg_engine.connect() as conn:
            result = conn.execute(text("""
                INSERT INTO documents (filename, content_hash, fields, metadata, quality_score, embedding_vector)
                VALUES (:filename, :hash, :fields, :metadata, :quality, :embedding)
                ON CONFLICT (content_hash) DO UPDATE SET
                    processed_at = CURRENT_TIMESTAMP
                RETURNING id
            """), {
                'filename': doc_data['filename'],
                'hash': content_hash,
                'fields': json.dumps(doc_data['fields']),
                'metadata': json.dumps(doc_data.get('metadata', {})),
                'quality': doc_data['quality_score'],
                'embedding': pickle.dumps(doc_data.get('embedding', []))
            })
            conn.commit()
            return result.fetchone()[0]
    
    def get_all_documents(self) -> List[Dict]:
        """ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ"""
        with self.pg_engine.connect() as conn:
            result = conn.execute(text("SELECT * FROM documents ORDER BY processed_at DESC"))
            return [dict(row._mapping) for row in result]
    
    def cache_embeddings(self, key: str, embeddings: np.ndarray, ttl: int = 3600):
        """ì„ë² ë”© ìºì‹±"""
        if self.redis_client:
            self.redis_client.setex(key, ttl, pickle.dumps(embeddings))
    
    def get_cached_embeddings(self, key: str) -> Optional[np.ndarray]:
        """ìºì‹œëœ ì„ë² ë”© ì¡°íšŒ"""
        if self.redis_client:
            data = self.redis_client.get(key)
            if data:
                return pickle.loads(data)
        return None

class EnhancedOntologyManager:
    """í–¥ìƒëœ ì˜¨í†¨ë¡œì§€ ê´€ë¦¬ì - ìë™ ì—…ë°ì´íŠ¸ ì§€ì›"""
    
    def __init__(self, ontology_path: str = "ontology.ttl", auto_update: bool = True):
        self.graph = Graph()
        self.ontology_path = ontology_path
        self.field_mappings = {}
        self.domain_embeddings = {}
        self.auto_update = auto_update
        self.update_queue = Queue()
        self.load_ontology()
        
        if auto_update:
            self._start_update_thread()
    
    def load_ontology(self):
        """ì˜¨í†¨ë¡œì§€ ë¡œë“œ ë° ë„ë©”ì¸ íŠ¹í™” ì„ë² ë”© êµ¬ì¶•"""
        try:
            self.graph.parse(self.ontology_path, format="ttl")
            self._build_field_mappings()
            self._build_domain_embeddings()
            logger.info(f"âœ… Enhanced ontology loaded: {len(self.graph)} triples")
        except Exception as e:
            logger.warning(f"âš ï¸ Ontology file not found: {e}")
            self._create_enhanced_ontology()
    
    def _build_domain_embeddings(self):
        """ë„ë©”ì¸ íŠ¹í™” ì„ë² ë”© êµ¬ì¶•"""
        engineering_terms = [
            "pressure", "temperature", "flow rate", "capacity", "diameter",
            "design pressure", "operating pressure", "maximum pressure",
            "design temperature", "operating temperature", "maximum temperature",
            "centrifugal pump", "heat exchanger", "reactor", "vessel",
            "piping", "instrumentation", "control valve", "safety valve"
        ]
        
        # ë„ë©”ì¸ íŠ¹í™” SentenceTransformer íŒŒì¸íŠœë‹ (ì‹œë®¬ë ˆì´ì…˜)
        model = SentenceTransformer('all-MiniLM-L6-v2')
        for term in engineering_terms:
            embedding = model.encode([term])[0]
            self.domain_embeddings[term.lower()] = embedding
    
    def _create_enhanced_ontology(self):
        """í–¥ìƒëœ ê¸°ë³¸ ì˜¨í†¨ë¡œì§€ ìƒì„±"""
        enhanced_mappings = {
            # ì••ë ¥ ê´€ë ¨
            'pressure': 'eng:Pressure',
            'press': 'eng:Pressure',
            'design pressure': 'eng:DesignPressure',
            'design press': 'eng:DesignPressure',
            'operating pressure': 'eng:OperatingPressure',
            'oper pressure': 'eng:OperatingPressure',
            'max pressure': 'eng:MaximumPressure',
            'maximum pressure': 'eng:MaximumPressure',
            
            # ì˜¨ë„ ê´€ë ¨
            'temperature': 'eng:Temperature',
            'temp': 'eng:Temperature',
            'design temperature': 'eng:DesignTemperature',
            'design temp': 'eng:DesignTemperature',
            'operating temperature': 'eng:OperatingTemperature',
            'oper temperature': 'eng:OperatingTemperature',
            'max temperature': 'eng:MaximumTemperature',
            'maximum temperature': 'eng:MaximumTemperature',
            
            # ìœ ëŸ‰ ê´€ë ¨
            'flow': 'eng:FlowRate',
            'flow rate': 'eng:FlowRate',
            'capacity': 'eng:Capacity',
            'volume': 'eng:Volume',
            
            # ì¹˜ìˆ˜ ê´€ë ¨
            'diameter': 'eng:Diameter',
            'length': 'eng:Length',
            'height': 'eng:Height',
            'width': 'eng:Width'
        }
        self.field_mappings = enhanced_mappings
    
    def _start_update_thread(self):
        """ìë™ ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ ì‹œì‘"""
        def update_worker():
            while True:
                try:
                    update_data = self.update_queue.get(timeout=60)
                    self._process_ontology_update(update_data)
                    self.update_queue.task_done()
                except:
                    continue
        
        update_thread = threading.Thread(target=update_worker, daemon=True)
        update_thread.start()
    
    def _process_ontology_update(self, update_data: Dict):
        """ì˜¨í†¨ë¡œì§€ ìë™ ì—…ë°ì´íŠ¸ ì²˜ë¦¬"""
        new_field = update_data.get('field_name', '').lower()
        standard_field = update_data.get('standard_field')
        
        if new_field and standard_field:
            self.field_mappings[new_field] = standard_field
            logger.info(f"ğŸ”„ Ontology updated: {new_field} â†’ {standard_field}")
    
    def find_standard_field(self, field_name: str, use_similarity: bool = True) -> Tuple[str, float]:
        """í‘œì¤€ í•„ë“œëª… ì°¾ê¸° (ìœ ì‚¬ë„ í¬í•¨)"""
        normalized = field_name.lower().strip()
        
        # ì§ì ‘ ë§¤ì¹­
        if normalized in self.field_mappings:
            return self.field_mappings[normalized], 1.0
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        if use_similarity and self.domain_embeddings:
            model = SentenceTransformer('all-MiniLM-L6-v2')
            field_embedding = model.encode([normalized])[0]
            
            best_match = field_name
            best_score = 0.0
            
            for term, term_embedding in self.domain_embeddings.items():
                similarity = cosine_similarity([field_embedding], [term_embedding])[0][0]
                if similarity > best_score and similarity > 0.7:
                    best_score = similarity
                    best_match = self.field_mappings.get(term, term)
            
            return best_match, best_score
        
        return field_name, 0.0

class AdaptiveMultiGNN(nn.Module):
    """ì ì‘í˜• Multi-GNN - ë™ì  ì„ê³„ê°’ ë° ë©€í‹°ëª¨ë‹¬ ì§€ì›"""
    
    def __init__(self, num_nodes, num_relations, hidden_dim=128, out_dim=64, num_heads=8):
        super(AdaptiveMultiGNN, self).__init__()
        self.hidden_dim = hidden_dim
        self.out_dim = out_dim
        self.num_heads = num_heads
        
        # Multi-scale GNN layers
        self.rgcn = RGCNConv(num_nodes, hidden_dim, num_relations)
        self.sage = SAGEConv(hidden_dim, hidden_dim)
        self.gat = GATConv(hidden_dim, out_dim, heads=num_heads, concat=False)
        
        # Heterogeneous graph support
        self.hetero_conv = HeteroConv({
            ('document', 'has_field', 'field'): SAGEConv((-1, -1), hidden_dim),
            ('field', 'has_value', 'value'): SAGEConv((-1, -1), hidden_dim),
            ('field', 'similar_to', 'field'): GATConv((-1, -1), hidden_dim, heads=4, concat=False)
        })
        
        # Adaptive threshold network
        self.threshold_net = nn.Sequential(
            nn.Linear(out_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )
        
        # Classification heads
        self.document_classifier = nn.Linear(out_dim, num_nodes)
        self.field_classifier = nn.Linear(out_dim, num_nodes)
        self.similarity_predictor = nn.Linear(out_dim * 2, 1)
        
        # Dropout for regularization
        self.dropout = nn.Dropout(0.3)
        
    def forward(self, x, edge_index, edge_type, node_types=None):
        # Multi-scale feature extraction
        x1 = F.relu(self.rgcn(x, edge_index, edge_type))
        x1 = self.dropout(x1)
        
        x2 = F.relu(self.sage(x1, edge_index))
        x2 = self.dropout(x2)
        
        x3 = self.gat(x2, edge_index)
        
        return x3
    
    def compute_adaptive_threshold(self, emb1, emb2):
        """ë™ì  ì„ê³„ê°’ ê³„ì‚°"""
        combined = torch.cat([emb1, emb2], dim=-1)
        threshold = self.threshold_net(combined)
        return threshold
    
    def predict_similarity(self, emb1, emb2):
        """ìœ ì‚¬ë„ ì˜ˆì¸¡"""
        combined = torch.cat([emb1, emb2], dim=-1)
        similarity = torch.sigmoid(self.similarity_predictor(combined))
        return similarity

class AdvancedSemanticMatcher:
    """ê³ ê¸‰ ì‹œë§¨í‹± ë§¤ì¹­ ì—”ì§„ - ë™ì  ì„ê³„ê°’, ë„ë©”ì¸ íŠ¹í™”"""
    
    def __init__(self, ontology_manager: EnhancedOntologyManager, db_manager: DatabaseManager):
        self.ontology = ontology_manager
        self.db_manager = db_manager
        self.domain_model = None
        self.general_model = None
        self.field_embeddings_cache = {}
        self._load_models()
    
    @st.cache_resource
    def _load_models(_self):
        """ëª¨ë¸ ë¡œë“œ (ìºì‹œë¨)"""
        # ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ (ì—”ì§€ë‹ˆì–´ë§)
        domain_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # ì¼ë°˜ ëª¨ë¸
        general_model = SentenceTransformer('all-mpnet-base-v2')
        
        return domain_model, general_model
    
    def match_fields_advanced(self, field1: str, field2: str, 
                            gnn_embeddings=None, context: Dict = None) -> Dict[str, float]:
        """ê³ ê¸‰ í•„ë“œ ë§¤ì¹­ - ë‹¤ì¤‘ ì ìˆ˜ ë°˜í™˜"""
        
        if self.domain_model is None or self.general_model is None:
            self.domain_model, self.general_model = self._load_models()
        
        results = {
            'ontology_score': 0.0,
            'domain_semantic_score': 0.0,
            'general_semantic_score': 0.0,
            'gnn_score': 0.0,
            'context_score': 0.0,
            'final_score': 0.0,
            'confidence': 0.0
        }
        
        # Level 1: Ontology ë§¤ì¹­
        std_field1, conf1 = self.ontology.find_standard_field(field1)
        std_field2, conf2 = self.ontology.find_standard_field(field2)
        
        if std_field1 == std_field2 and conf1 > 0.8 and conf2 > 0.8:
            results['ontology_score'] = 1.0
        
        # Level 2: ë„ë©”ì¸ íŠ¹í™” ì„ë² ë”© ë§¤ì¹­
        try:
            # ìºì‹œëœ ì„ë² ë”© í™•ì¸
            cache_key1 = f"domain_emb_{hashlib.md5(field1.encode()).hexdigest()}"
            cache_key2 = f"domain_emb_{hashlib.md5(field2.encode()).hexdigest()}"
            
            emb1 = self.db_manager.get_cached_embeddings(cache_key1)
            emb2 = self.db_manager.get_cached_embeddings(cache_key2)
            
            if emb1 is None:
                emb1 = self.domain_model.encode([field1])[0]
                self.db_manager.cache_embeddings(cache_key1, emb1)
            
            if emb2 is None:
                emb2 = self.domain_model.encode([field2])[0]
                self.db_manager.cache_embeddings(cache_key2, emb2)
            
            results['domain_semantic_score'] = cosine_similarity([emb1], [emb2])[0][0]
            
        except Exception as e:
            logger.warning(f"Domain embedding failed: {e}")
        
        # Level 3: ì¼ë°˜ ì„ë² ë”© ë§¤ì¹­
        try:
            gen_emb1 = self.general_model.encode([field1])[0]
            gen_emb2 = self.general_model.encode([field2])[0]
            results['general_semantic_score'] = cosine_similarity([gen_emb1], [gen_emb2])[0][0]
        except Exception as e:
            logger.warning(f"General embedding failed: {e}")
        
        # Level 4: GNN ì„ë² ë”© ë§¤ì¹­
        if gnn_embeddings is not None:
            try:
                # GNN ì„ë² ë”©ì„ ì´ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚° (êµ¬í˜„ ì˜ˆì •)
                results['gnn_score'] = 0.5  # í”Œë ˆì´ìŠ¤í™€ë”
            except Exception as e:
                logger.warning(f"GNN embedding failed: {e}")
        
        # Level 5: ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­
        if context:
            try:
                # ë¬¸ì„œ ë‚´ ìœ„ì¹˜, ì£¼ë³€ í•„ë“œ ë“±ì„ ê³ ë ¤í•œ ì ìˆ˜
                results['context_score'] = self._calculate_context_score(field1, field2, context)
            except Exception as e:
                logger.warning(f"Context matching failed: {e}")
        
        # ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ìµœì¢… ì ìˆ˜
        weights = self._calculate_dynamic_weights(results)
        final_score = (
            weights['ontology'] * results['ontology_score'] +
            weights['domain'] * results['domain_semantic_score'] +
            weights['general'] * results['general_semantic_score'] +
            weights['gnn'] * results['gnn_score'] +
            weights['context'] * results['context_score']
        )
        
        results['final_score'] = final_score
        results['confidence'] = self._calculate_confidence(results)
        
        return results
    
    def _calculate_dynamic_weights(self, scores: Dict[str, float]) -> Dict[str, float]:
        """ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        base_weights = {
            'ontology': 0.4,
            'domain': 0.3,
            'general': 0.15,
            'gnn': 0.1,
            'context': 0.05
        }
        
        # ì˜¨í†¨ë¡œì§€ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
        if scores['ontology_score'] > 0.9:
            base_weights['ontology'] = 0.6
            base_weights['domain'] = 0.2
            base_weights['general'] = 0.1
        
        # ë„ë©”ì¸ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
        elif scores['domain_semantic_score'] > 0.8:
            base_weights['domain'] = 0.4
            base_weights['ontology'] = 0.3
        
        return base_weights
    
    def _calculate_context_score(self, field1: str, field2: str, context: Dict) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ë¬¸ì„œ ë‚´ ìœ„ì¹˜ ìœ ì‚¬ì„±
        pos1 = context.get('position1', {})
        pos2 = context.get('position2', {})
        
        if pos1 and pos2:
            # ê°™ì€ ì„¹ì…˜ì— ìˆìœ¼ë©´ ì ìˆ˜ ì¦ê°€
            if pos1.get('section') == pos2.get('section'):
                score += 0.3
            
            # ë¹„ìŠ·í•œ í–‰ ë²ˆí˜¸ë©´ ì ìˆ˜ ì¦ê°€
            row_diff = abs(pos1.get('row', 0) - pos2.get('row', 0))
            if row_diff <= 2:
                score += 0.2
        
        return min(score, 1.0)
    
    def _calculate_confidence(self, scores: Dict[str, float]) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        # ì—¬ëŸ¬ ì ìˆ˜ê°€ ì¼ì¹˜í• ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
        score_values = [
            scores['ontology_score'],
            scores['domain_semantic_score'],
            scores['general_semantic_score'],
            scores['gnn_score']
        ]
        
        # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        std_dev = np.std([s for s in score_values if s > 0])
        confidence = max(0.0, 1.0 - std_dev)
        
        return confidence

class RealTimeProcessor:
    """ì‹¤ì‹œê°„ ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, max_workers: int = 4):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.processing_queue = Queue()
        self.result_cache = {}
        
    async def process_document_async(self, pdf_file, filename: str) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ë¬¸ì„œ ì²˜ë¦¬"""
        loop = asyncio.get_event_loop()
        
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        result = await loop.run_in_executor(
            self.executor,
            self._process_document_sync,
            pdf_file,
            filename
        )
        
        return result
    
    def _process_document_sync(self, pdf_file, filename: str) -> Dict[str, Any]:
        """ë™ê¸° ë¬¸ì„œ ì²˜ë¦¬ (ë‚´ë¶€ìš©)"""
        # ê¸°ì¡´ PDF ì²˜ë¦¬ ë¡œì§
        processor = AdvancedPDFProcessor()
        return processor.extract_text_and_tables(pdf_file)

class AdvancedPDFProcessor:
    """ê³ ê¸‰ PDF ì²˜ë¦¬ê¸° - ë©€í‹°í”„ë¡œì„¸ì‹±, í’ˆì§ˆ í–¥ìƒ"""
    
    def __init__(self, use_multiprocessing: bool = True):
        self.text_quality_threshold = 0.7
        self.use_multiprocessing = use_multiprocessing
        self.table_detection_confidence = 0.8
    
    def extract_text_and_tables(self, pdf_file) -> Dict[str, Any]:
        """ê³ ê¸‰ í…ìŠ¤íŠ¸ ë° í‘œ ì¶”ì¶œ"""
        results = {
            'text': '',
            'tables': [],
            'fields': {},
            'quality_score': 0.0,
            'metadata': {},
            'structure_analysis': {}
        }
        
        try:
            with pdfplumber.open(pdf_file) as pdf:
                if self.use_multiprocessing and len(pdf.pages) > 1:
                    # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ í˜ì´ì§€ ë³‘ë ¬ ì²˜ë¦¬
                    results = self._process_pages_parallel(pdf.pages)
                else:
                    # ìˆœì°¨ ì²˜ë¦¬
                    results = self._process_pages_sequential(pdf.pages)
                
                # í›„ì²˜ë¦¬
                results = self._post_process_results(results)
                
        except Exception as e:
            logger.error(f"âŒ Enhanced PDF processing error: {e}")
            
        return results
    
    def _process_pages_parallel(self, pages) -> Dict[str, Any]:
        """ë³‘ë ¬ í˜ì´ì§€ ì²˜ë¦¬"""
        with mp.Pool(processes=min(4, len(pages))) as pool:
            page_results = pool.map(self._process_single_page, 
                                   [(i, page) for i, page in enumerate(pages)])
        
        # ê²°ê³¼ ë³‘í•©
        return self._merge_page_results(page_results)
    
    def _process_pages_sequential(self, pages) -> Dict[str, Any]:
        """ìˆœì°¨ í˜ì´ì§€ ì²˜ë¦¬"""
        page_results = []
        for i, page in enumerate(pages):
            result = self._process_single_page((i, page))
            page_results.append(result)
        
        return self._merge_page_results(page_results)
    
    def _process_single_page(self, page_data) -> Dict[str, Any]:
        """ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬"""
        page_num, page = page_data
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        page_text = page.extract_text() or ""
        
        # í‘œ ì¶”ì¶œ - í–¥ìƒëœ ì•Œê³ ë¦¬ì¦˜
        tables = self._extract_tables_enhanced(page)
        
        # í•„ë“œ ì¶”ì¶œ
        fields = self._extract_fields_enhanced(page_text, tables)
        
        return {
            'page_num': page_num,
            'text': page_text,
            'tables': tables,
            'fields': fields
        }
    
    def _extract_tables_enhanced(self, page) -> List[Dict[str, Any]]:
        """í–¥ìƒëœ í‘œ ì¶”ì¶œ"""
        tables = []
        
        # ê¸°ë³¸ í‘œ ì¶”ì¶œ
        raw_tables = page.extract_tables()
        
        for table in raw_tables:
            if not table or len(table) < 2:
                continue
            
            processed_table = self._analyze_table_structure(table)
            if processed_table['confidence'] >= self.table_detection_confidence:
                tables.append(processed_table)
        
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ í‘œ ê°ì§€
        text_tables = self._detect_text_tables(page.extract_text())
        tables.extend(text_tables)
        
        return tables
    
    def _analyze_table_structure(self, table: List[List[str]]) -> Dict[str, Any]:
        """í‘œ êµ¬ì¡° ë¶„ì„"""
        if not table or len(table) < 2:
            return {'confidence': 0.0}
        
        # í—¤ë” ë¶„ì„
        headers = [cell.strip() if cell else "" for cell in table[0]]
        data_rows = table[1:]
        
        # í‘œ í’ˆì§ˆ í‰ê°€
        confidence = self._evaluate_table_quality(headers, data_rows)
        
        # í•„ë“œ-ê°’ ìŒ ì¶”ì¶œ
        field_value_pairs = {}
        structure_type = "unknown"
        
        if confidence >= 0.7:
            if len(headers) == 2 and any("field" in h.lower() or "name" in h.lower() for h in headers):
                # í•„ë“œ-ê°’ í…Œì´ë¸”
                structure_type = "field_value_pairs"
                field_value_pairs = self._extract_field_value_pairs(data_rows)
            
            elif any(keyword in ' '.join(headers).lower() 
                    for keyword in ['pressure', 'temperature', 'flow', 'capacity']):
                # ì—”ì§€ë‹ˆì–´ë§ ì‚¬ì–‘ í…Œì´ë¸”
                structure_type = "engineering_specification"
                field_value_pairs = self._extract_engineering_fields(headers, data_rows)
        
        return {
            'headers': headers,
            'data': data_rows,
            'field_value_pairs': field_value_pairs,
            'structure_type': structure_type,
            'confidence': confidence,
            'quality_metrics': self._calculate_table_metrics(headers, data_rows)
        }
    
    def _evaluate_table_quality(self, headers: List[str], data_rows: List[List[str]]) -> float:
        """í‘œ í’ˆì§ˆ í‰ê°€"""
        score = 0.0
        
        # í—¤ë” í’ˆì§ˆ
        if headers and any(headers):
            score += 0.3
        
        # ë°ì´í„° ì¼ê´€ì„±
        if data_rows:
            avg_cols = sum(len(row) for row in data_rows) / len(data_rows)
            if avg_cols >= len(headers) * 0.8:  # 80% ì´ìƒ ì±„ì›Œì ¸ ìˆìŒ
                score += 0.4
        
        # ì—”ì§€ë‹ˆì–´ë§ í‚¤ì›Œë“œ ì¡´ì¬
        all_text = ' '.join(headers + [cell for row in data_rows for cell in row if cell])
        engineering_keywords = ['pressure', 'temperature', 'flow', 'capacity', 'design', 'operating']
        if any(keyword in all_text.lower() for keyword in engineering_keywords):
            score += 0.3
        
        return min(score, 1.0)
    
    def _extract_field_value_pairs(self, data_rows: List[List[str]]) -> Dict[str, str]:
        """í•„ë“œ-ê°’ ìŒ ì¶”ì¶œ"""
        pairs = {}
        
        for row in data_rows:
            if len(row) >= 2 and row[0] and row[1]:
                field_name = str(row[0]).strip()
                field_value = str(row[1]).strip()
                
                # í•„ë“œëª… ì •ê·œí™”
                field_name = re.sub(r'\s+', ' ', field_name)
                field_name = re.sub(r'[^\w\s]', '', field_name)
                
                if len(field_name) > 2 and len(field_value) > 0:
                    pairs[field_name] = field_value
        
        return pairs
    
    def _extract_engineering_fields(self, headers: List[str], data_rows: List[List[str]]) -> Dict[str, str]:
        """ì—”ì§€ë‹ˆì–´ë§ í•„ë“œ ì¶”ì¶œ"""
        fields = {}
        
        for row in data_rows:
            for i, (header, value) in enumerate(zip(headers, row)):
                if header and value and header.strip() and value.strip():
                    field_key = f"{header.strip()}_{i}"
                    fields[field_key] = value.strip()
        
        return fields
    
    def _merge_page_results(self, page_results: List[Dict]) -> Dict[str, Any]:
        """í˜ì´ì§€ ê²°ê³¼ ë³‘í•©"""
        merged = {
            'text': '',
            'tables': [],
            'fields': {},
            'quality_score': 0.0,
            'metadata': {},
            'structure_analysis': {}
        }
        
        for result in page_results:
            merged['text'] += result['text'] + "\n"
            merged['tables'].extend(result['tables'])
            merged['fields'].update(result['fields'])
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        merged['quality_score'] = self._calculate_overall_quality(merged)
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        merged['metadata'] = {
            'total_pages': len(page_results),
            'total_tables': len(merged['tables']),
            'total_fields': len(merged['fields']),
            'processing_method': 'parallel' if self.use_multiprocessing else 'sequential'
        }
        
        return merged
    
    def _calculate_overall_quality(self, results: Dict) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        base_score = 0.2
        
        # í…ìŠ¤íŠ¸ í’ˆì§ˆ
        if results['text'] and len(results['text']) > 100:
            base_score += 0.3
        
        # í‘œ í’ˆì§ˆ
        if results['tables']:
            table_scores = [t.get('confidence', 0) for t in results['tables']]
            avg_table_quality = sum(table_scores) / len(table_scores)
            base_score += 0.3 * avg_table_quality
        
        # í•„ë“œ ì¶”ì¶œ í’ˆì§ˆ
        if results['fields']:
            field_count = len(results['fields'])
            field_score = min(field_count * 0.02, 0.2)
            base_score += field_score
        
        return min(base_score, 1.0)

class EnterpriseAnalyzer:
    """ê¸°ì—…ìš© í†µí•© ë¶„ì„ê¸°"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.db_manager = DatabaseManager(config.get('database', {}))
        
        # í–¥ìƒëœ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.ontology_manager = EnhancedOntologyManager(
            config.get('ontology_path', 'ontology.ttl'),
            auto_update=config.get('auto_update_ontology', True)
        )
        
        self.semantic_matcher = AdvancedSemanticMatcher(
            self.ontology_manager, 
            self.db_manager
        )
        
        self.pdf_processor = AdvancedPDFProcessor(
            use_multiprocessing=config.get('use_multiprocessing', True)
        )
        
        self.realtime_processor = RealTimeProcessor(
            max_workers=config.get('max_workers', 4)
        )
        
        # GNN ëª¨ë¸
        self.gnn_model = None
        self.node_embeddings = None
        self.training_history = []
        
        # ì§€ì‹ ê·¸ë˜í”„
        self.knowledge_graph = nx.DiGraph()
        
        logger.info("ğŸš€ Enterprise Multi-GNN Knowledge Graph Analyzer initialized")
        logger.info(f"âœ… GPU available: {torch.cuda.is_available()}")
        logger.info(f"âœ… Device: {device}")
    
    async def process_document_enterprise(self, pdf_file, filename: str) -> Dict[str, Any]:
        """ê¸°ì—…ìš© ë¬¸ì„œ ì²˜ë¦¬"""
        # ì‹¤ì‹œê°„ ë¹„ë™ê¸° ì²˜ë¦¬
        extraction_result = await self.realtime_processor.process_document_async(pdf_file, filename)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        doc_data = {
            'filename': filename,
            'fields': extraction_result['fields'],
            'metadata': extraction_result.get('metadata', {}),
            'quality_score': extraction_result['quality_score']
        }
        
        doc_id = self.db_manager.save_document(doc_data)
        
        # ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
        self._update_knowledge_graph_enterprise(doc_id, extraction_result['fields'])
        
        logger.info(f"ğŸ“„ Document processed: {filename} (ID: {doc_id})")
        
        return {
            'doc_id': doc_id,
            'extraction_result': extraction_result,
            'graph_stats': {
                'nodes': len(self.knowledge_graph.nodes),
                'edges': len(self.knowledge_graph.edges)
            }
        }
    
    def _update_knowledge_graph_enterprise(self, doc_id: int, fields: Dict[str, str]):
        """ê¸°ì—…ìš© ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸"""
        doc_node = f"doc_{doc_id}"
        self.knowledge_graph.add_node(doc_node, type="document", doc_id=doc_id)
        
        for field_name, field_value in fields.items():
            # í‘œì¤€í™”ëœ í•„ë“œëª… ì‚¬ìš©
            std_field, confidence = self.ontology_manager.find_standard_field(field_name)
            
            field_node = f"field_{std_field}_{doc_id}"
            value_node = f"value_{hashlib.md5(field_value.encode()).hexdigest()}"
            
            # ë…¸ë“œ ì¶”ê°€
            self.knowledge_graph.add_node(
                field_node, 
                type="field", 
                name=std_field, 
                original_name=field_name,
                confidence=confidence
            )
            
            self.knowledge_graph.add_node(
                value_node, 
                type="value", 
                value=field_value,
                data_type=self._detect_data_type(field_value)
            )
            
            # ì—£ì§€ ì¶”ê°€
            self.knowledge_graph.add_edge(doc_node, field_node, relation="has_field")
            self.knowledge_graph.add_edge(field_node, value_node, relation="has_value")
            
            # í•„ë“œ ê°„ ìœ ì‚¬ë„ ì—£ì§€ ì¶”ê°€
            self._add_similarity_edges(field_node, std_field)
    
    def _detect_data_type(self, value: str) -> str:
        """ë°ì´í„° íƒ€ì… ê°ì§€"""
        value = value.strip()
        
        # ìˆ«ì íŒ¨í„´
        if re.match(r'^-?\d+\.?\d*$', value):
            return "numeric"
        
        # ë‹¨ìœ„ê°€ ìˆëŠ” ìˆ«ì
        if re.match(r'^-?\d+\.?\d*\s*[a-zA-Z]+', value):
            return "measurement"
        
        # ë‚ ì§œ íŒ¨í„´
        if re.match(r'\d{4}-\d{2}-\d{2}', value):
            return "date"
        
        # ì¹´í…Œê³ ë¦¬ (ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì§§ì€ í…ìŠ¤íŠ¸)
        if len(value) < 50 and value[0].isupper():
            return "category"
        
        return "text"
    
    def _add_similarity_edges(self, new_field_node: str, std_field: str):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ì—£ì§€ ì¶”ê°€"""
        for node in self.knowledge_graph.nodes():
            if (node.startswith("field_") and 
                node != new_field_node and 
                self.knowledge_graph.nodes[node].get('type') == 'field'):
                
                other_std_field = self.knowledge_graph.nodes[node].get('name', '')
                
                # ê°™ì€ í‘œì¤€ í•„ë“œë©´ ìœ ì‚¬ë„ ì—£ì§€ ì¶”ê°€
                if std_field == other_std_field:
                    self.knowledge_graph.add_edge(
                        new_field_node, 
                        node, 
                        relation="similar_to",
                        similarity=1.0
                    )
    
    def train_adaptive_gnn(self, hyperparameters: Dict = None) -> Dict[str, Any]:
        """ì ì‘í˜• GNN í›ˆë ¨"""
        if len(self.knowledge_graph.nodes) < 10:
            return {"error": "Need at least 10 nodes for enterprise GNN training"}
        
        # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        default_hyperparams = {
            'hidden_dim': 128,
            'out_dim': 64,
            'num_heads': 8,
            'learning_rate': 0.001,
            'epochs': 200,
            'batch_size': 32,
            'dropout': 0.3
        }
        
        if hyperparameters:
            default_hyperparams.update(hyperparameters)
        
        logger.info("ğŸ¤– Training Adaptive Multi-GNN model...")
        
        # ê·¸ë˜í”„ ë°ì´í„° ì¤€ë¹„
        nodes = list(self.knowledge_graph.nodes())
        edges = list(self.knowledge_graph.edges())
        
        # GPUë¡œ ì´ë™
        node_to_idx = {node: idx for idx, node in enumerate(nodes)}
        edge_index = torch.tensor(
            [[node_to_idx[e[0]], node_to_idx[e[1]]] for e in edges], 
            device=device
        ).t()
        
        # ê´€ê³„ íƒ€ì… ë§¤í•‘
        relation_types = list(set(nx.get_edge_attributes(self.knowledge_graph, 'relation').values()))
        relation_to_idx = {rel: idx for idx, rel in enumerate(relation_types)}
        
        edge_type = torch.tensor([
            relation_to_idx.get(
                self.knowledge_graph[e[0]][e[1]].get('relation', 'unknown'), 0
            ) for e in edges
        ], device=device)
        
        # ì´ˆê¸° ë…¸ë“œ íŠ¹ì„±
        num_nodes = len(nodes)
        x = torch.eye(num_nodes, device=device)
        
        # ì ì‘í˜• Multi-GNN ëª¨ë¸ ì´ˆê¸°í™”
        self.gnn_model = AdaptiveMultiGNN(
            num_nodes=num_nodes,
            num_relations=len(relation_types),
            hidden_dim=default_hyperparams['hidden_dim'],
            out_dim=default_hyperparams['out_dim'],
            num_heads=default_hyperparams['num_heads']
        ).to(device)
        
        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
        optimizer = torch.optim.AdamW(
            self.gnn_model.parameters(), 
            lr=default_hyperparams['learning_rate'],
            weight_decay=1e-4
        )
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=default_hyperparams['epochs']
        )
        
        # í›ˆë ¨ ë£¨í”„
        self.gnn_model.train()
        training_losses = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for epoch in range(default_hyperparams['epochs']):
            optimizer.zero_grad()
            
            # Forward pass
            embeddings = self.gnn_model(x, edge_index, edge_type)
            
            # ë‹¤ì¤‘ ì†ì‹¤ í•¨ìˆ˜
            # 1. ì¬êµ¬ì„± ì†ì‹¤
            reconstructed = self.gnn_model.document_classifier(embeddings)
            reconstruction_loss = F.mse_loss(reconstructed, x)
            
            # 2. ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ (ìœ ì‚¬í•œ í•„ë“œëŠ” ê°€ê¹ê²Œ, ë‹¤ë¥¸ í•„ë“œëŠ” ë©€ê²Œ)
            contrastive_loss = self._compute_contrastive_loss(embeddings, nodes)
            
            # 3. ì •ê·œí™” ì†ì‹¤
            reg_loss = sum(p.pow(2.0).sum() for p in self.gnn_model.parameters())
            
            # ì´ ì†ì‹¤
            total_loss = (reconstruction_loss + 
                         0.1 * contrastive_loss + 
                         1e-5 * reg_loss)
            
            total_loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
            torch.nn.utils.clip_grad_norm_(self.gnn_model.parameters(), max_norm=1.0)
            
            optimizer.step()
            scheduler.step()
            
            training_losses.append(total_loss.item())
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_bar.progress((epoch + 1) / default_hyperparams['epochs'])
            if epoch % 20 == 0:
                status_text.text(f"Epoch {epoch}/{default_hyperparams['epochs']}, "
                               f"Loss: {total_loss.item():.4f}, "
                               f"LR: {scheduler.get_last_lr()[0]:.6f}")
        
        # í•™ìŠµëœ ì„ë² ë”© ì €ì¥
        self.gnn_model.eval()
        with torch.no_grad():
            self.node_embeddings = self.gnn_model(x, edge_index, edge_type).cpu().numpy()
        
        # ëª¨ë¸ ì €ì¥
        model_data = {
            'model_state': self.gnn_model.state_dict(),
            'hyperparameters': default_hyperparams,
            'node_mapping': node_to_idx,
            'relation_mapping': relation_to_idx
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ëª¨ë¸ ì €ì¥
        with self.db_manager.pg_engine.connect() as conn:
            conn.execute(text("""
                INSERT INTO gnn_models (model_name, model_data, hyperparameters, performance_metrics)
                VALUES (:name, :data, :hyperparams, :metrics)
            """), {
                'name': f"adaptive_gnn_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'data': pickle.dumps(model_data),
                'hyperparams': json.dumps(default_hyperparams),
                'metrics': json.dumps({
                    'final_loss': training_losses[-1],
                    'training_losses': training_losses[-10:],  # ë§ˆì§€ë§‰ 10ê°œë§Œ ì €ì¥
                    'num_epochs': len(training_losses)
                })
            })
            conn.commit()
        
        progress_bar.empty()
        status_text.empty()
        
        self.training_history = training_losses
        
        logger.info("âœ… Adaptive Multi-GNN training completed")
        
        return {
            "status": "success",
            "num_nodes": num_nodes,
            "num_relations": len(relation_types),
            "final_loss": training_losses[-1],
            "training_epochs": len(training_losses),
            "model_saved": True,
            "device": str(device)
        }
    
    def _compute_contrastive_loss(self, embeddings: torch.Tensor, nodes: List[str]) -> torch.Tensor:
        """ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ ê³„ì‚°"""
        loss = 0.0
        num_pairs = 0
        
        # ê°™ì€ íƒ€ì…ì˜ ë…¸ë“œë“¤ì€ ê°€ê¹ê²Œ, ë‹¤ë¥¸ íƒ€ì…ì€ ë©€ê²Œ
        for i, node1 in enumerate(nodes):
            node1_type = self.knowledge_graph.nodes[node1].get('type', 'unknown')
            
            for j, node2 in enumerate(nodes[i+1:], i+1):
                node2_type = self.knowledge_graph.nodes[node2].get('type', 'unknown')
                
                emb1 = embeddings[i]
                emb2 = embeddings[j]
                
                similarity = F.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0))
                
                if node1_type == node2_type:
                    # ê°™ì€ íƒ€ì…: ìœ ì‚¬ë„ ë†’ì´ê¸°
                    loss += (1 - similarity) ** 2
                else:
                    # ë‹¤ë¥¸ íƒ€ì…: ìœ ì‚¬ë„ ë‚®ì¶”ê¸°
                    loss += similarity ** 2
                
                num_pairs += 1
                
                # ê³„ì‚°ëŸ‰ ì œí•œ
                if num_pairs > 1000:
                    break
            
            if num_pairs > 1000:
                break
        
        return loss / max(num_pairs, 1)
    
    def compare_documents_enterprise(self) -> Dict[str, Any]:
        """ê¸°ì—…ìš© ë¬¸ì„œ ë¹„êµ"""
        documents = self.db_manager.get_all_documents()
        
        if len(documents) < 2:
            return {"error": "Need at least 2 documents for comparison"}
        
        logger.info("ğŸ” Enterprise document comparison with advanced semantic matching...")
        
        comparison_results = {}
        
        for i, doc1 in enumerate(documents):
            for j, doc2 in enumerate(documents[i+1:], i+1):
                doc1_fields = json.loads(doc1['fields']) if isinstance(doc1['fields'], str) else doc1['fields']
                doc2_fields = json.loads(doc2['fields']) if isinstance(doc2['fields'], str) else doc2['fields']
                
                # ê³ ê¸‰ ë¹„êµ ìˆ˜í–‰
                comparison = self._compare_documents_advanced(
                    doc1_fields, doc2_fields, 
                    doc1['filename'], doc2['filename']
                )
                
                comparison_key = f"doc_{doc1['id']}_vs_doc_{doc2['id']}"
                comparison_results[comparison_key] = {
                    'doc1_name': doc1['filename'],
                    'doc2_name': doc2['filename'],
                    'doc1_quality': doc1['quality_score'],
                    'doc2_quality': doc2['quality_score'],
                    'comparison': comparison
                }
                
                # ë§¤í•‘ ê²°ê³¼ ì €ì¥
                for match in comparison['matched_fields']:
                    self._save_field_mapping(
                        match['field1'], match['field2'], 
                        match['final_score'], match['confidence']
                    )
        
        return comparison_results
    
    def _compare_documents_advanced(self, doc1_fields: Dict, doc2_fields: Dict, 
                                  filename1: str, filename2: str) -> Dict[str, Any]:
        """ê³ ê¸‰ ë¬¸ì„œ ë¹„êµ"""
        comparison_result = {
            'matched_fields': [],
            'doc1_unique': [],
            'doc2_unique': [],
            'field_mappings': {},
            'similarity_matrix': {},
            'overall_similarity': 0.0,
            'confidence_scores': {},
            'semantic_clusters': []
        }
        
        # ëª¨ë“  í•„ë“œ ì¡°í•©ì— ëŒ€í•´ ê³ ê¸‰ ìœ ì‚¬ë„ ê³„ì‚°
        similarity_matrix = {}
        confidence_matrix = {}
        
        for field1 in doc1_fields:
            for field2 in doc2_fields:
                # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ êµ¬ì„±
                context = {
                    'position1': {'document': filename1},
                    'position2': {'document': filename2}
                }
                
                match_result = self.semantic_matcher.match_fields_advanced(
                    field1, field2, self.node_embeddings, context
                )
                
                similarity_matrix[(field1, field2)] = match_result['final_score']
                confidence_matrix[(field1, field2)] = match_result['confidence']
        
        # ë™ì  ì„ê³„ê°’ ê³„ì‚°
        all_scores = list(similarity_matrix.values())
        dynamic_threshold = np.percentile(all_scores, 75) if all_scores else 0.7
        
        # ìµœì  ë§¤ì¹­ ì°¾ê¸° (í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ ê·¼ì‚¬)
        used_fields2 = set()
        
        # ë†’ì€ ì ìˆ˜ë¶€í„° ë§¤ì¹­
        sorted_pairs = sorted(similarity_matrix.items(), key=lambda x: x[1], reverse=True)
        
        for (field1, field2), score in sorted_pairs:
            if (field1 not in comparison_result['field_mappings'] and 
                field2 not in used_fields2 and 
                score >= dynamic_threshold):
                
                confidence = confidence_matrix[(field1, field2)]
                
                comparison_result['matched_fields'].append({
                    'field1': field1,
                    'field2': field2,
                    'final_score': score,
                    'confidence': confidence,
                    'value1': doc1_fields[field1],
                    'value2': doc2_fields[field2],
                    'threshold_used': dynamic_threshold
                })
                
                comparison_result['field_mappings'][field1] = field2
                used_fields2.add(field2)
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ í•„ë“œë“¤
        for field1 in doc1_fields:
            if field1 not in comparison_result['field_mappings']:
                comparison_result['doc1_unique'].append(field1)
        
        for field2 in doc2_fields:
            if field2 not in used_fields2:
                comparison_result['doc2_unique'].append(field2)
        
        # ì „ì²´ ìœ ì‚¬ë„ ê³„ì‚° (ê°€ì¤‘í‰ê· )
        if comparison_result['matched_fields']:
            weighted_scores = [match['final_score'] * match['confidence'] 
                             for match in comparison_result['matched_fields']]
            total_weight = sum(match['confidence'] for match in comparison_result['matched_fields'])
            
            if total_weight > 0:
                comparison_result['overall_similarity'] = sum(weighted_scores) / total_weight
            
            # Jaccard ìœ ì‚¬ë„ë¡œ ì •ê·œí™”
            total_fields = len(doc1_fields) + len(doc2_fields) - len(comparison_result['matched_fields'])
            jaccard_factor = len(comparison_result['matched_fields']) / total_fields
            comparison_result['overall_similarity'] *= jaccard_factor
        
        comparison_result['similarity_matrix'] = similarity_matrix
        comparison_result['dynamic_threshold'] = dynamic_threshold
        
        return comparison_result
    
    def _save_field_mapping(self, field1: str, field2: str, score: float, confidence: float):
        """í•„ë“œ ë§¤í•‘ ì €ì¥"""
        try:
            with self.db_manager.pg_engine.connect() as conn:
                conn.execute(text("""
                    INSERT INTO field_mappings (source_field, target_field, similarity_score, mapping_type)
                    VALUES (:field1, :field2, :score, :type)
                    ON CONFLICT DO NOTHING
                """), {
                    'field1': field1,
                    'field2': field2,
                    'score': score,
                    'type': 'semantic_advanced'
                })
                conn.commit()
        except Exception as e:
            logger.warning(f"Failed to save field mapping: {e}")

# Streamlit ì•± ì„¤ì •
def get_default_config():
    """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
    return {
        'database': {
            'pg_host': os.getenv('PG_HOST', 'localhost'),
            'pg_port': os.getenv('PG_PORT', '5432'),
            'pg_user': os.getenv('PG_USER', 'postgres'),
            'pg_password': os.getenv('PG_PASSWORD', 'password'),
            'pg_database': os.getenv('PG_DATABASE', 'knowledge_graph'),
            'redis_host': os.getenv('REDIS_HOST', 'localhost'),
            'redis_port': os.getenv('REDIS_PORT', '6379')
        },
        'ontology_path': 'ontology.ttl',
        'auto_update_ontology': True,
        'use_multiprocessing': True,
        'max_workers': 4
    }

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'enterprise_analyzer' not in st.session_state:
    config = get_default_config()
    st.session_state.enterprise_analyzer = EnterpriseAnalyzer(config)
    st.success("âœ… Enterprise Multi-GNN Knowledge Graph Analyzer initialized")

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #2E86AB, #A23B72);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .enterprise-badge {
        background: linear-gradient(45deg, #FF6B35, #F7931E);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 25px;
        font-weight: bold;
        display: inline-block;
        margin: 1rem 0;
    }
    .feature-card {
        background: #f8f9fa;
        border-left: 4px solid #2E86AB;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0.25rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸš€ Enterprise Multi-GNN Knowledge Graph Analyzer</h1>', 
                unsafe_allow_html=True)
    
    st.markdown('<div class="enterprise-badge">ğŸ¢ Enterprise Edition</div>', 
                unsafe_allow_html=True)
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## ğŸ¯ Enterprise Features")
        
        st.markdown("""
        <div class="feature-card">
            <strong>âœ… GPU Acceleration</strong><br>
            CUDA support for training
        </div>
        <div class="feature-card">
            <strong>ğŸ—„ï¸ Database Integration</strong><br>
            PostgreSQL + Redis + FAISS
        </div>
        <div class="feature-card">
            <strong>ğŸ¤– Adaptive Multi-GNN</strong><br>
            Dynamic thresholds & multimodal
        </div>
        <div class="feature-card">
            <strong>âš¡ Real-time Processing</strong><br>
            Async + multiprocessing
        </div>
        <div class="feature-card">
            <strong>ğŸ§  Auto-learning Ontology</strong><br>
            Self-updating knowledge base
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        analyzer = st.session_state.enterprise_analyzer
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        col1, col2 = st.columns(2)
        with col1:
            st.metric("GPU Available", "âœ…" if torch.cuda.is_available() else "âŒ")
            st.metric("Graph Nodes", len(analyzer.knowledge_graph.nodes))
        
        with col2:
            st.metric("Device", str(device))
            st.metric("Graph Edges", len(analyzer.knowledge_graph.edges))
        
        if analyzer.gnn_model is not None:
            st.success("ğŸ¤– Adaptive GNN: Trained")
        else:
            st.info("ğŸ¤– Adaptive GNN: Ready to train")
    
    # ë©”ì¸ íƒ­
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“„ Document Processing", 
        "ğŸ¤– AI Training", 
        "ğŸ” Intelligent Comparison", 
        "ğŸ•¸ï¸ Graph Visualization",
        "ğŸ“Š Analytics Dashboard"
    ])
    
    with tab1:
        st.markdown("## ğŸ“„ Enterprise Document Processing")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            uploaded_files = st.file_uploader(
                "Upload PDF documents for enterprise analysis",
                type=['pdf'],
                accept_multiple_files=True,
                help="Supports parallel processing and advanced table extraction"
            )
        
        with col2:
            st.markdown("### Processing Options")
            use_multiprocessing = st.checkbox("Enable Multiprocessing", value=True)
            use_gpu = st.checkbox("GPU Acceleration", value=torch.cuda.is_available())
            quality_threshold = st.slider("Quality Threshold", 0.0, 1.0, 0.7)
        
        if uploaded_files:
            for uploaded_file in uploaded_files:
                if st.button(f"ğŸš€ Process {uploaded_file.name}", key=f"process_{uploaded_file.name}"):
                    with st.spinner(f"Enterprise processing: {uploaded_file.name}..."):
                        try:
                            # ë¹„ë™ê¸° ì²˜ë¦¬ (Streamlitì—ì„œëŠ” ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬)
                            result = st.session_state.enterprise_analyzer.pdf_processor.extract_text_and_tables(uploaded_file)
                            
                            # ë¬¸ì„œ ì €ì¥
                            doc_data = {
                                'filename': uploaded_file.name,
                                'fields': result['fields'],
                                'metadata': result.get('metadata', {}),
                                'quality_score': result['quality_score']
                            }
                            
                            doc_id = st.session_state.enterprise_analyzer.db_manager.save_document(doc_data)
                            
                            # ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
                            st.session_state.enterprise_analyzer._update_knowledge_graph_enterprise(doc_id, result['fields'])
                            
                            # ê²°ê³¼ í‘œì‹œ
                            st.markdown(f"""
                            <div class="success-box">
                                <h4>âœ… {uploaded_file.name} processed successfully</h4>
                                <div style="display: flex; gap: 1rem; margin: 1rem 0;">
                                    <div class="metric-card">
                                        <h3>{result['quality_score']:.2f}</h3>
                                        <p>Quality Score</p>
                                    </div>
                                    <div class="metric-card">
                                        <h3>{len(result['fields'])}</h3>
                                        <p>Fields Extracted</p>
                                    </div>
                                    <div class="metric-card">
                                        <h3>{len(result['tables'])}</h3>
                                        <p>Tables Found</p>
                                    </div>
                                    <div class="metric-card">
                                        <h3>{result['metadata'].get('total_pages', 1)}</h3>
                                        <p>Pages Processed</p>
                                    </div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
                            if result['fields']:
                                with st.expander("ğŸ“‹ Extracted Fields Details"):
                                    fields_df = pd.DataFrame([
                                        {
                                            "Field Name": k, 
                                            "Value": v[:100] + "..." if len(v) > 100 else v,
                                            "Data Type": st.session_state.enterprise_analyzer._detect_data_type(v),
                                            "Standard Field": st.session_state.enterprise_analyzer.ontology_manager.find_standard_field(k)[0]
                                        } 
                                        for k, v in result['fields'].items()
                                    ])
                                    st.dataframe(fields_df, use_container_width=True)
                            
                            # í‘œ êµ¬ì¡° ë¶„ì„ ê²°ê³¼
                            if result['tables']:
                                with st.expander("ğŸ“Š Table Structure Analysis"):
                                    for i, table in enumerate(result['tables']):
                                        st.write(f"**Table {i+1}:**")
                                        st.write(f"- Structure Type: {table.get('structure_type', 'unknown')}")
                                        st.write(f"- Confidence: {table.get('confidence', 0):.2f}")
                                        st.write(f"- Field-Value Pairs: {len(table.get('field_value_pairs', {}))}")
                                        
                                        if table.get('headers'):
                                            st.write(f"- Headers: {', '.join(table['headers'][:5])}...")
                            
                        except Exception as e:
                            st.error(f"âŒ Error processing {uploaded_file.name}: {str(e)}")
    
    with tab2:
        st.markdown("## ğŸ¤– Adaptive Multi-GNN Training")
        
        analyzer = st.session_state.enterprise_analyzer
        
        if len(analyzer.knowledge_graph.nodes) < 10:
            st.warning("âš ï¸ Need at least 10 nodes for enterprise GNN training. Please upload more documents.")
        else:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.info(f"ğŸ“Š Current graph: {len(analyzer.knowledge_graph.nodes)} nodes, "
                       f"{len(analyzer.knowledge_graph.edges)} edges")
                
                # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
                st.markdown("### ğŸ›ï¸ Hyperparameters")
                
                col_a, col_b = st.columns(2)
                with col_a:
                    hidden_dim = st.selectbox("Hidden Dimension", [64, 128, 256], index=1)
                    out_dim = st.selectbox("Output Dimension", [32, 64, 128], index=1)
                    num_heads = st.selectbox("Attention Heads", [4, 8, 16], index=1)
                
                with col_b:
                    learning_rate = st.selectbox("Learning Rate", [0.0001, 0.001, 0.01], index=1)
                    epochs = st.slider("Training Epochs", 50, 500, 200)
                    dropout = st.slider("Dropout Rate", 0.1, 0.5, 0.3)
                
                hyperparams = {
                    'hidden_dim': hidden_dim,
                    'out_dim': out_dim,
                    'num_heads': num_heads,
                    'learning_rate': learning_rate,
                    'epochs': epochs,
                    'dropout': dropout
                }
            
            with col2:
                st.markdown("### ğŸš€ Training Status")
                
                if analyzer.gnn_model is not None:
                    st.success("âœ… Model trained")
                    if analyzer.training_history:
                        st.line_chart(pd.DataFrame({
                            'Loss': analyzer.training_history[-50:]  # ìµœê·¼ 50 ì—í¬í¬
                        }))
                else:
                    st.info("ğŸ¯ Ready to train")
            
            if st.button("ğŸš€ Train Adaptive Multi-GNN", type="primary"):
                with st.spinner("Training adaptive multi-GNN model..."):
                    result = analyzer.train_adaptive_gnn(hyperparams)
                    
                    if "error" in result:
                        st.error(f"âŒ {result['error']}")
                    else:
                        st.markdown(f"""
                        <div class="success-box">
                            <h4>âœ… Adaptive Multi-GNN training completed!</h4>
                            <div style="display: flex; gap: 1rem; margin: 1rem 0;">
                                <div class="metric-card">
                                    <h3>{result['num_nodes']}</h3>
                                    <p>Nodes</p>
                                </div>
                                <div class="metric-card">
                                    <h3>{result['num_relations']}</h3>
                                    <p>Relations</p>
                                </div>
                                <div class="metric-card">
                                    <h3>{result['final_loss']:.6f}</h3>
                                    <p>Final Loss</p>
                                </div>
                                <div class="metric-card">
                                    <h3>{result['training_epochs']}</h3>
                                    <p>Epochs</p>
                                </div>
                            </div>
                            <p><strong>Device:</strong> {result['device']}</p>
                            <p><strong>Model Saved:</strong> {result['model_saved']}</p>
                        </div>
                        """, unsafe_allow_html=True)
        
        # ì•„í‚¤í…ì²˜ ì„¤ëª…
        with st.expander("ğŸ§  Adaptive Multi-GNN Architecture"):
            st.markdown("""
            ### ğŸ”„ Enhanced Pipeline: R-GCN â†’ GraphSAGE â†’ GAT â†’ Adaptive Threshold
            
            **ğŸ¯ Key Improvements:**
            
            1. **Adaptive Threshold Network**
               - Dynamic similarity thresholds based on context
               - Learned from training data patterns
               - Reduces false positives in field matching
            
            2. **Multi-scale Feature Extraction**
               - R-GCN: Relation-aware convolution
               - GraphSAGE: Neighborhood aggregation  
               - GAT: Attention-weighted features
            
            3. **Contrastive Learning**
               - Similar fields pushed together in embedding space
               - Different types pushed apart
               - Improves semantic understanding
            
            4. **Regularization & Optimization**
               - Dropout for generalization
               - Gradient clipping for stability
               - Cosine annealing learning rate schedule
            
            5. **GPU Acceleration**
               - Full CUDA support
               - Optimized tensor operations
               - Batch processing capabilities
            """)
    
    with tab3:
        st.markdown("## ğŸ” Intelligent Document Comparison")
        
        analyzer = st.session_state.enterprise_analyzer
        
        # ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡
        documents = analyzer.db_manager.get_all_documents()
        
        if len(documents) < 2:
            st.warning("âš ï¸ Need at least 2 documents for intelligent comparison.")
        else:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"ğŸ“š {len(documents)} documents available for comparison")
                
                # ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
                with st.expander("ğŸ“‹ Available Documents"):
                    docs_df = pd.DataFrame([
                        {
                            "ID": doc['id'],
                            "Filename": doc['filename'],
                            "Quality Score": f"{doc['quality_score']:.2f}",
                            "Fields Count": len(json.loads(doc['fields']) if isinstance(doc['fields'], str) else doc['fields']),
                            "Processed": doc['processed_at']
                        }
                        for doc in documents
                    ])
                    st.dataframe(docs_df, use_container_width=True)
            
            with col2:
                st.markdown("### âš™ï¸ Comparison Settings")
                use_gnn_embeddings = st.checkbox("Use GNN Embeddings", value=analyzer.gnn_model is not None)
                include_context = st.checkbox("Include Context Analysis", value=True)
                min_confidence = st.slider("Minimum Confidence", 0.0, 1.0, 0.5)
            
            if st.button("ğŸ” Start Intelligent Comparison", type="primary"):
                with st.spinner("Performing intelligent document comparison..."):
                    results = analyzer.compare_documents_enterprise()
                    
                    if "error" in results:
                        st.error(f"âŒ {results['error']}")
                    else:
                        st.success(f"âœ… Compared {len(results)} document pairs")
                        
                        # ì „ì²´ í†µê³„
                        total_matches = sum(len(comp['comparison']['matched_fields']) for comp in results.values())
                        avg_similarity = np.mean([comp['comparison']['overall_similarity'] for comp in results.values()])
                        
                        st.markdown(f"""
                        <div class="success-box">
                            <h4>ğŸ“Š Comparison Summary</h4>
                            <div style="display: flex; gap: 1rem; margin: 1rem 0;">
                                <div class="metric-card">
                                    <h3>{len(results)}</h3>
                                    <p>Document Pairs</p>
                                </div>
                                <div class="metric-card">
                                    <h3>{total_matches}</h3>
                                    <p>Total Matches</p>
                                </div>
                                <div class="metric-card">
                                    <h3>{avg_similarity:.3f}</h3>
                                    <p>Avg Similarity</p>
                                </div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ê°œë³„ ë¹„êµ ê²°ê³¼
                        for comp_key, comp_data in results.items():
                            comparison = comp_data['comparison']
                            
                            with st.expander(f"ğŸ“‹ {comp_data['doc1_name']} â†” {comp_data['doc2_name']}"):
                                
                                # ìš”ì•½ ë©”íŠ¸ë¦­
                                col_a, col_b, col_c, col_d = st.columns(4)
                                with col_a:
                                    st.metric("Overall Similarity", f"{comparison['overall_similarity']:.3f}")
                                with col_b:
                                    st.metric("Matched Fields", len(comparison['matched_fields']))
                                with col_c:
                                    st.metric("Dynamic Threshold", f"{comparison.get('dynamic_threshold', 0.7):.3f}")
                                with col_d:
                                    unique_count = len(comparison['doc1_unique']) + len(comparison['doc2_unique'])
                                    st.metric("Unique Fields", unique_count)
                                
                                # ë§¤ì¹­ëœ í•„ë“œ ìƒì„¸
                                if comparison['matched_fields']:
                                    st.write("**ğŸ¯ Matched Fields:**")
                                    
                                    # ì‹ ë¢°ë„ë³„ í•„í„°ë§
                                    high_confidence_matches = [
                                        match for match in comparison['matched_fields'] 
                                        if match['confidence'] >= min_confidence
                                    ]
                                    
                                    if high_confidence_matches:
                                        matched_df = pd.DataFrame([
                                            {
                                                "Doc1 Field": match['field1'],
                                                "Doc2 Field": match['field2'], 
                                                "Score": f"{match['final_score']:.3f}",
                                                "Confidence": f"{match['confidence']:.3f}",
                                                "Doc1 Value": match['value1'][:50] + "..." if len(match['value1']) > 50 else match['value1'],
                                                "Doc2 Value": match['value2'][:50] + "..." if len(match['value2']) > 50 else match['value2']
                                            }
                                            for match in high_confidence_matches
                                        ])
                                        st.dataframe(matched_df, use_container_width=True)
                                    else:
                                        st.info(f"No matches above confidence threshold {min_confidence}")
                                
                                # ê³ ìœ  í•„ë“œë“¤
                                if comparison['doc1_unique'] or comparison['doc2_unique']:
                                    col_x, col_y = st.columns(2)
                                    
                                    with col_x:
                                        if comparison['doc1_unique']:
                                            st.write(f"**ğŸ“„ Unique to {comp_data['doc1_name']}:**")
                                            for field in comparison['doc1_unique'][:10]:  # ìµœëŒ€ 10ê°œ
                                                st.write(f"â€¢ {field}")
                                    
                                    with col_y:
                                        if comparison['doc2_unique']:
                                            st.write(f"**ğŸ“„ Unique to {comp_data['doc2_name']}:**")
                                            for field in comparison['doc2_unique'][:10]:  # ìµœëŒ€ 10ê°œ
                                                st.write(f"â€¢ {field}")
        
        # ê³ ê¸‰ ë§¤ì¹­ ì „ëµ ì„¤ëª…
        with st.expander("ğŸ¯ Advanced Semantic Matching Strategy"):
            st.markdown("""
            ### ğŸ§  5-Level Intelligent Matching
            
            **Level 1: Ontology Direct Matching (40% weight)**
            - Uses ontology.ttl for standard field mappings
            - 100% accuracy for known mappings
            - Auto-learning from new field discoveries
            
            **Level 2: Domain-Specific Embeddings (30% weight)**  
            - Engineering-focused SentenceTransformer model
            - Specialized vocabulary understanding
            - Industry-specific terminology recognition
            
            **Level 3: General Semantic Embeddings (15% weight)**
            - Universal language understanding
            - Handles diverse field naming patterns
            - Robustness for unknown domains
            
            **Level 4: GNN Learned Embeddings (10% weight)**
            - Graph-aware contextual understanding
            - Relationship-informed similarities
            - Document structure consideration
            
            **Level 5: Contextual Analysis (5% weight)**
            - Document position information
            - Surrounding field context
            - Structural pattern recognition
            
            **ğŸ¯ Dynamic Features:**
            - Adaptive threshold calculation
            - Confidence-weighted scoring
            - Real-time learning from user feedback
            """)
    
    with tab4:
        st.markdown("## ğŸ•¸ï¸ Interactive Knowledge Graph Visualization")
        
        analyzer = st.session_state.enterprise_analyzer
        viz_data = analyzer.create_visualization_data()
        
        if not viz_data['nodes']:
            st.info("ğŸ“„ No data to visualize. Please upload and process documents first.")
        else:
            col1, col2 = st.columns([3, 1])
            
            with col2:
                st.markdown("### ğŸ›ï¸ Visualization Controls")
                
                # í•„í„° ì˜µì…˜
                node_types = list(set(node['type'] for node in viz_data['nodes']))
                selected_types = st.multiselect("Node Types", node_types, default=node_types)
                
                # ë ˆì´ì•„ì›ƒ ì˜µì…˜
                layout_type = st.selectbox("Layout Algorithm", 
                                         ["spring", "circular", "kamada_kawai", "spectral"])
                
                # ì‹œê°í™” ì˜µì…˜
                show_labels = st.checkbox("Show Labels", value=True)
                node_size_factor = st.slider("Node Size", 0.5, 2.0, 1.0)
                edge_width_factor = st.slider("Edge Width", 0.5, 2.0, 1.0)
            
            with col1:
                # í•„í„°ë§ëœ ë°ì´í„°
                filtered_nodes = [node for node in viz_data['nodes'] if node['type'] in selected_types]
                filtered_node_ids = {node['id'] for node in filtered_nodes}
                filtered_edges = [edge for edge in viz_data['edges'] 
                                if edge['source'] in filtered_node_ids and edge['target'] in filtered_node_ids]
                
                if filtered_nodes:
                    # NetworkX ê·¸ë˜í”„ ìƒì„±
                    G = nx.Graph()
                    for node in filtered_nodes:
                        G.add_node(node['id'], **node)
                    for edge in filtered_edges:
                        G.add_edge(edge['source'], edge['target'], **edge)
                    
                    # ë ˆì´ì•„ì›ƒ ê³„ì‚°
                    if layout_type == "spring":
                        pos = nx.spring_layout(G, k=3, iterations=50)
                    elif layout_type == "circular":
                        pos = nx.circular_layout(G)
                    elif layout_type == "kamada_kawai":
                        pos = nx.kamada_kawai_layout(G)
                    else:  # spectral
                        pos = nx.spectral_layout(G)
                    
                    # ìƒ‰ìƒ ë§¤í•‘
                    color_map = {
                        'document': '#2E86AB',
                        'field': '#A23B72', 
                        'value': '#F18F01'
                    }
                    
                    # Plotly ê·¸ë˜í”„ ìƒì„±
                    node_trace = go.Scatter(
                        x=[pos[node['id']][0] for node in filtered_nodes],
                        y=[pos[node['id']][1] for node in filtered_nodes],
                        mode='markers+text' if show_labels else 'markers',
                        text=[node['label'][:15] + '...' if len(node['label']) > 15 else node['label'] 
                              for node in filtered_nodes] if show_labels else [],
                        textposition="middle center",
                        marker=dict(
                            size=[20 * node_size_factor if node['type'] == 'document' 
                                  else 15 * node_size_factor if node['type'] == 'field' 
                                  else 10 * node_size_factor for node in filtered_nodes],
                            color=[color_map.get(node['type'], '#888888') for node in filtered_nodes],
                            line=dict(width=2, color='white'),
                            opacity=0.8
                        ),
                        hoverinfo='text',
                        hovertext=[f"Type: {node['type']}<br>Label: {node['label']}<br>ID: {node['id']}" 
                                  for node in filtered_nodes],
                        name="Nodes"
                    )
                    
                    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
                    edge_traces = []
                    for edge in filtered_edges:
                        x0, y0 = pos[edge['source']]
                        x1, y1 = pos[edge['target']]
                        
                        edge_traces.append(go.Scatter(
                            x=[x0, x1, None],
                            y=[y0, y1, None],
                            mode='lines',
                            line=dict(
                                width=1 * edge_width_factor, 
                                color='rgba(125,125,125,0.5)'
                            ),
                            hoverinfo='text',
                            hovertext=f"Relation: {edge.get('relation', 'unknown')}",
                            showlegend=False
                        ))
                    
                    # í”¼ê·œì–´ ìƒì„±
                    fig = go.Figure(data=[node_trace] + edge_traces)
                    fig.update_layout(
                        title="Enterprise Knowledge Graph - Interactive Visualization",
                        showlegend=True,
                        hovermode='closest',
                        margin=dict(b=20,l=5,r=5,t=40),
                        annotations=[dict(
                            text=f"Nodes: {len(filtered_nodes)} | Edges: {len(filtered_edges)} | Layout: {layout_type}",
                            showarrow=False,
                            xref="paper", yref="paper",
                            x=0.005, y=-0.002,
                            xanchor='left', yanchor='bottom',
                            font=dict(color="gray", size=12)
                        )],
                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        height=600,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                else:
                    st.warning("No nodes match the selected filters.")
            
            # ê·¸ë˜í”„ í†µê³„
            st.markdown("### ğŸ“Š Graph Statistics")
            
            col_a, col_b, col_c, col_d = st.columns(4)
            
            with col_a:
                st.metric("Total Nodes", len(viz_data['nodes']))
            with col_b:
                st.metric("Total Edges", len(viz_data['edges']))
            with col_c:
                if viz_data['nodes']:
                    G_full = nx.Graph()
                    for edge in viz_data['edges']:
                        G_full.add_edge(edge['source'], edge['target'])
                    density = nx.density(G_full)
                    st.metric("Graph Density", f"{density:.3f}")
            with col_d:
                node_types_count = {}
                for node in viz_data['nodes']:
                    node_type = node['type']
                    node_types_count[node_type] = node_types_count.get(node_type, 0) + 1
                
                most_common_type = max(node_types_count.items(), key=lambda x: x[1]) if node_types_count else ("None", 0)
                st.metric("Dominant Type", f"{most_common_type[0]} ({most_common_type[1]})")
            
            # ë…¸ë“œ íƒ€ì… ë¶„í¬
            with st.expander("ğŸ“ˆ Node Type Distribution"):
                if node_types_count:
                    type_df = pd.DataFrame([
                        {"Node Type": k, "Count": v, "Percentage": f"{(v/len(viz_data['nodes'])*100):.1f}%"}
                        for k, v in node_types_count.items()
                    ])
                    st.dataframe(type_df, use_container_width=True)
                    
                    # íŒŒì´ ì°¨íŠ¸
                    fig_pie = px.pie(
                        values=list(node_types_count.values()),
                        names=list(node_types_count.keys()),
                        title="Node Type Distribution"
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
    
    with tab5:
        st.markdown("## ğŸ“Š Enterprise Analytics Dashboard")
        
        analyzer = st.session_state.enterprise_analyzer
        documents = analyzer.db_manager.get_all_documents()
        
        if not documents:
            st.info("ğŸ“ˆ Upload and process documents to see analytics.")
        else:
            # ì „ì²´ í†µê³„
            st.markdown("### ğŸ“ˆ Overall Performance Metrics")
            
            col1, col2, col3, col4 = st.columns(4)
            
            total_fields = sum(len(json.loads(doc['fields']) if isinstance(doc['fields'], str) else doc['fields']) for doc in documents)
            avg_quality = np.mean([doc['quality_score'] for doc in documents])
            
            with col1:
                st.metric("Total Documents", len(documents))
            with col2:
                st.metric("Total Fields Extracted", total_fields)
            with col3:
                st.metric("Average Quality Score", f"{avg_quality:.3f}")
            with col4:
                processing_efficiency = total_fields / len(documents) if documents else 0
                st.metric("Processing Efficiency", f"{processing_efficiency:.1f} fields/doc")
            
            # ì‹œê³„ì—´ ë¶„ì„
            st.markdown("### ğŸ“… Processing Timeline")
            
            # ë¬¸ì„œ ì²˜ë¦¬ ì‹œê°„ë³„ ë¶„í¬
            docs_df = pd.DataFrame([
                {
                    "Date": pd.to_datetime(doc['processed_at']),
                    "Filename": doc['filename'],
                    "Quality Score": doc['quality_score'],
                    "Fields Count": len(json.loads(doc['fields']) if isinstance(doc['fields'], str) else doc['fields'])
                }
                for doc in documents
            ])
            
            docs_df['Date'] = docs_df['Date'].dt.date
            
            # ì¼ë³„ ì²˜ë¦¬ í†µê³„
            daily_stats = docs_df.groupby('Date').agg({
                'Filename': 'count',
                'Quality Score': 'mean',
                'Fields Count': 'sum'
            }).rename(columns={'Filename': 'Documents Processed'})
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                fig_timeline = px.line(
                    daily_stats.reset_index(),
                    x='Date',
                    y='Documents Processed',
                    title="Documents Processed Over Time",
                    markers=True
                )
                st.plotly_chart(fig_timeline, use_container_width=True)
            
            with col_b:
                fig_quality = px.line(
                    daily_stats.reset_index(),
                    x='Date',
                    y='Quality Score',
                    title="Average Quality Score Over Time",
                    markers=True
                )
                st.plotly_chart(fig_quality, use_container_width=True)
            
            # í’ˆì§ˆ ì ìˆ˜ ë¶„í¬
            st.markdown("### ğŸ“Š Quality Score Distribution")
            
            fig_hist = px.histogram(
                docs_df,
                x='Quality Score',
                nbins=20,
                title="Quality Score Distribution",
                labels={'count': 'Number of Documents'}
            )
            st.plotly_chart(fig_hist, use_container_width=True)
            
            # í•„ë“œ ì¶”ì¶œ íš¨ìœ¨ì„±
            st.markdown("### ğŸ¯ Field Extraction Analysis")
            
            col_x, col_y = st.columns(2)
            
            with col_x:
                fig_scatter = px.scatter(
                    docs_df,
                    x='Quality Score',
                    y='Fields Count',
                    hover_data=['Filename'],
                    title="Quality Score vs Fields Extracted",
                    trendline="ols"
                )
                st.plotly_chart(fig_scatter, use_container_width=True)
            
            with col_y:
                # ìƒìœ„/í•˜ìœ„ ì„±ëŠ¥ ë¬¸ì„œ
                st.markdown("#### ğŸ† Top Performing Documents")
                top_docs = docs_df.nlargest(5, 'Quality Score')[['Filename', 'Quality Score', 'Fields Count']]
                st.dataframe(top_docs, use_container_width=True)
                
                st.markdown("#### âš ï¸ Low Quality Documents")
                low_docs = docs_df.nsmallest(3, 'Quality Score')[['Filename', 'Quality Score', 'Fields Count']]
                st.dataframe(low_docs, use_container_width=True)
            
            # GNN í•™ìŠµ í†µê³„ (ìˆëŠ” ê²½ìš°)
            if analyzer.training_history:
                st.markdown("### ğŸ¤– GNN Training Performance")
                
                training_df = pd.DataFrame({
                    'Epoch': range(len(analyzer.training_history)),
                    'Loss': analyzer.training_history
                })
                
                fig_training = px.line(
                    training_df,
                    x='Epoch',
                    y='Loss',
                    title="GNN Training Loss Over Epochs",
                    log_y=True
                )
                st.plotly_chart(fig_training, use_container_width=True)
                
                # í•™ìŠµ í†µê³„
                final_loss = analyzer.training_history[-1]
                initial_loss = analyzer.training_history[0]
                improvement = ((initial_loss - final_loss) / initial_loss) * 100
                
                col_stat1, col_stat2, col_stat3 = st.columns(3)
                with col_stat1:
                    st.metric("Initial Loss", f"{initial_loss:.6f}")
                with col_stat2:
                    st.metric("Final Loss", f"{final_loss:.6f}")
                with col_stat3:
                    st.metric("Improvement", f"{improvement:.1f}%")
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´
            st.markdown("### ğŸ’» System Resources")
            
            col_res1, col_res2, col_res3 = st.columns(3)
            
            with col_res1:
                st.info(f"**Device:** {device}")
                st.info(f"**CUDA Available:** {'âœ…' if torch.cuda.is_available() else 'âŒ'}")
            
            with col_res2:
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                    st.info(f"**GPU Memory:** {gpu_memory:.1f} GB")
                    st.info(f"**GPU Name:** {torch.cuda.get_device_name(0)}")
            
            with col_res3:
                import psutil
                cpu_percent = psutil.cpu_percent()
                memory_percent = psutil.virtual_memory().percent
                st.info(f"**CPU Usage:** {cpu_percent:.1f}%")
                st.info(f"**Memory Usage:** {memory_percent:.1f}%")

if __name__ == "__main__":
    main()